{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentum Trading Strategy implemented in Python on a 500 Stocks universe [Beginner friendly]\n",
    "By AlgoVibes (Youtube)\n",
    "https://www.youtube.com/watch?v=L2nhNvIAyBI\n",
    "\n",
    "Description:<br>\n",
    "Get list of S&P500 stocks<br>\n",
    "Download price data for all<br>\n",
    "Concatenate into one dataframe<br>\n",
    "Calculate percent change<br>\n",
    "Resample to monthly period<br>\n",
    "\n",
    "To Do:<br>\n",
    "    Use start_date and end_date in process_ticker function, but just to trim returned data.<br>\n",
    "    Change benchmark to use equal weighted assets used by the strategy<br>\n",
    "    Allow for holding 100% cash if all other assets have negative returns.<br>\n",
    "    v3: Add trailing stop: try monthly, then daily<br>\n",
    "        After stop triggers, don't get back in until next month<br>\n",
    "        Alternatively, get back in after things go positive<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import sys\n",
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "%matplotlib inline\n",
    "import quantstats as qs\n",
    "qs.extend_pandas() # # extend pandas functionality with metrics, etc.\n",
    "sys.path.append('/home/lantro/Documents/Algo Trading/Stock Price DB')\n",
    "#from get_ticker_data_from_db_v2 import process_ticker\n",
    "from StockPriceData import process_ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set variables \n",
    "data_folder = '/home/lantro/Documents/Algo Trading/Data'\n",
    "start_date = '2020-01-01'#'1962-01-02'\n",
    "end_date = '2022-08-23'\n",
    "get_latest_data = True # Getting latest prices from DB is slow, so we can read previously created csv\n",
    "tickers = ['AAPL','AMZN','NFLX','AMD','NVDA','MSFT','WMT','IBM','KO']\n",
    "benchmark = ['^GSPC']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: when we get price df, we may want to replace all values below a certain threshold with 0 so that our algo doesn'tickers\n",
    "# trade them since they may appear to have great returns at times even though they're uninvestible at the time such as when they first list.\n",
    "# We should replace small values from beginning of df until the price meets our threshold. We probably want to leave in prices when they go below our threshold later.\n",
    "def get_prices(tickers):\n",
    "    if get_latest_data == True:\n",
    "        prices, symbols = [],[]\n",
    "        for ticker in tickers:\n",
    "            print(f'Processing {ticker}')\n",
    "            try:\n",
    "                #df = process_ticker(ticker,end_date)['Adj_Close']\n",
    "                df = process_ticker(ticker,start_date,end_date)['Adj_Close']\n",
    "                if not df.empty:\n",
    "                    print(f'Appending {ticker} to prices and symbols lists')\n",
    "                    prices.append(df)\n",
    "                    symbols.append(ticker)\n",
    "            except:\n",
    "                print(f'Unable to download data for {ticker}')\n",
    "            \n",
    "        all_prices = pd.concat(prices,axis=1) #Concatenate all ticker price dfs to one df\n",
    "        all_prices.columns = symbols # Rename column names based on tickers\n",
    "        all_prices.to_csv(f\"{data_folder}/all_sp500_prices.csv\", index=True) #Index is date\n",
    "    else:\n",
    "        #all_prices = pd.read_csv(f\"{data_folder}/all_sp500_prices.csv\", index_col=[0], header=0, parse_dates=True) #Index is date\n",
    "        all_prices = pd.read_csv(f\"{data_folder}/all_sp500_prices.csv\", index_col='Date', parse_dates=True)\n",
    "        #all_prices.index = pd.to_datetime(all_prices.index) #Not necessary if dates are parsed properly\n",
    "    return(all_prices)\n",
    "\n",
    "all_prices = get_prices(tickers)\n",
    "benchmark_prices = get_prices(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_prices.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prices\n",
    "#symbols\n",
    "#all_prices.index\n",
    "all_prices.head()\n",
    "all_prices.tail(10)\n",
    "#all_prices[all_prices > 0]\n",
    "latest_date_for_all = all_prices.dropna().index[-1] #This is the latest date where all tickers have data\n",
    "all_prices = all_prices.loc[:latest_date_for_all,:] #Trimming df to last date where all tickers had data\n",
    "all_prices.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See  how much data we have for each ticker\n",
    "for column in all_prices.columns[:-1]:\n",
    "    prices = all_prices[column][all_prices[column]>0]\n",
    "    print(f'{column}:  {prices.index[0]} - {prices.index[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate monthly returns\n",
    "if get_latest_data == True:\n",
    "    all_mtl_ret = all_prices.pct_change().resample('M').agg(lambda x : (x + 1).prod() -1)\n",
    "    all_mtl_ret['CASH'] = 0 # Add alternative for condition where everything is negative \n",
    "    all_mtl_ret.to_csv(f\"{data_folder}/all_mtl_ret.csv\", index=True) #Index is date\n",
    "else:\n",
    "    all_mtl_ret = pd.read_csv(f\"{data_folder}/all_mtl_ret.csv\", index_col='Date', parse_dates=True) #Index is date\n",
    "# IMPORTANT: We need to remove NaN and inf values from percentage returns df since stocks that trade at very low prices or zero will have\n",
    "# crazy return calculations when prices go from 0 to anything or vice versa.\n",
    "all_mtl_ret = all_mtl_ret.replace([np.inf, -np.inf, np.nan], 0)\n",
    "#Create a new prices df of only companies that have prices going back to the earliest date\n",
    "#earliest_prices = all_prices.loc[:, all_prices.iloc[0] > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mtl_ret.index\n",
    "all_mtl_ret.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead  of using something like the S&P500 as benchmark, we'll use an average of the returns for our defined assets\n",
    "#benchmark_returns = benchmark_prices.pct_change().dropna()\n",
    "benchmark_returns = all_prices.pct_change().dropna().mean(axis=1)\n",
    "#benchmark_monthly_returns = benchmark_prices.pct_change().resample('M').agg(lambda x : (x + 1).prod() -1)\n",
    "benchmark_monthly_returns = all_mtl_ret.mean(axis=1)\n",
    "#all_prices.tail().pct_change()#.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_returns\n",
    "benchmark_monthly_returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put it all together into a function that takes a lookback period (instead of just 12 months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mom_long(all_mtl_ret, lookback):\n",
    "    #Calculate rolling returns based on provided lookback period and return df\n",
    "    #Loop though rolling return df and identify 50 winning stocks\n",
    "    #Get return for following month for each winning stock\n",
    "    #Append returns to list\n",
    "    #Return the return for the series of returns \n",
    "    all_mtl_ret_lb = all_mtl_ret.rolling(lookback).agg(lambda x: (x+1).prod() - 1) #Calculate return for period\n",
    "    #See https://stackoverflow.com/questions/67168187/cannot-called-a-function-using-agg-method-in-pandas\n",
    "    all_mtl_ret_lb.dropna(inplace=True)\n",
    "    rets = {}\n",
    "    for row in range(len(all_mtl_ret_lb)-1): #Loop through all monthly periods & identify winners and losers\n",
    "        #curr = all_mtl_ret_lb.iloc[row] # All stocks for period\n",
    "        curr = all_mtl_ret_lb.iloc[row][all_mtl_ret_lb.iloc[row].ge(0)] # Only stocks with prices >= 0\n",
    "        win = curr.nlargest(2) # Take the top 2 stocks\n",
    "        win_ret = all_mtl_ret.loc[win.name + MonthEnd(1), win.index]\n",
    "        win_mean = win_ret.mean() #Average return of top stocks for period\n",
    "        rets[curr.name]=win_mean\n",
    "    #print(f'rets: {rets}')\n",
    "    ret_series = pd.Series(rets, dtype='float64')\n",
    "    # Use QS to calculate strategy stats here or just return the return series and do it later.\n",
    "    tot_ret = round(qs.stats.comp(ret_series),2)\n",
    "    sharpe_ratio = round(qs.stats.sharpe(ret_series),2)\n",
    "    max_dd = round(qs.stats.max_drawdown(ret_series),2)\n",
    "    print(f'Lookback:  {lookback},  Tot Ret: {tot_ret},  Sharpe Ratio:  {sharpe_ratio},  Max DD:  {max_dd}')\n",
    "    # Calculate returns manually for comparison\n",
    "    tot_return = (pd.Series(rets, dtype='float64') + 1).prod() - 1\n",
    "    cum_returns = (ret_series + 1).cumprod()\n",
    "    #print(f'Tot Cum Return:  {round((cum_returns.iloc[-1])-1,2)}')\n",
    "    return (ret_series)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate momentum results for several different lookback periods\n",
    "monthly_periods = None#120 # Specify \"None\" if you don't want to roll over the entire dataset\n",
    "lookback_periods = [3,6,12]\n",
    "period_weights = [.3333, .3333, .3333]\n",
    "# Improvement:  keep track of lookback period return series by adding to a dictionary, then we can reference later\n",
    "# to compare different weightings for top x lookback periods. This will allow us to try compare returns for different weightings.\n",
    "# (period 1 return * weight) + (period 2 return * wieght), etc\n",
    "'''You can compute a weighted average by multiplying its relative proportion or percentage by its value in sequence and\n",
    " adding those sums together. Thus, if a portfolio is made up of 55% stocks, 40% bonds, and 5% cash, those weights would be\n",
    "  multiplied by their annual performance to get a weighted average return.'''\n",
    "\n",
    "#all_mtl_ret_limited = all_mtl_ret.loc['2000-09-01':].copy()\n",
    "all_mtl_ret_limited = all_mtl_ret.iloc[:monthly_periods,:] # Trim df required number of periods (optional) \n",
    "print(f'Returns for {len(all_mtl_ret_limited)} months ({all_mtl_ret_limited.index[0].date()} - {all_mtl_ret_limited.index[-1].date()})')\n",
    "lookback_returns = {} # Dictionary to hold df of return series for specific lookback period.\n",
    "for lookback in lookback_periods:\n",
    "    lookback_returns[lookback] = mom_long(all_mtl_ret_limited, lookback)\n",
    "    #print(f'lookback_returns[{lookback}] last date: {lookback_returns[lookback].index[-1]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_returns_index = all_mtl_ret_limited.index #Create new df from index of existing to hold weighted returns\n",
    "weighted_returns = pd.DataFrame(index = weighted_returns_index)\n",
    "weighted_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for period_return in lookback_returns.keys():\n",
    "    lookback = lookback_periods[index]\n",
    "    print(f'Period weight for {lookback} period lookback:  {period_weights[index]}')\n",
    "    weighted_return = lookback_returns[period_return]*period_weights[index]\n",
    "    #print(f'weighted_return for {lookback} period lookback:  {weighted_return}')\n",
    "    weighted_returns[lookback] = weighted_return\n",
    "    index+=1\n",
    "weighted_returns = weighted_returns.replace([np.inf, -np.inf, np.nan], 0)\n",
    "returns = weighted_returns.sum(axis=1) # Add up weighted returns to get total return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_returns.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.head(11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass returns and benchmark to QuantStats to get return metrics\n",
    "#qs.reports.metrics(returns, '^GSPC', mode='basic')\n",
    "qs.reports.metrics(returns, benchmark_monthly_returns, mode='basic') # Compared returns to benchmark\n",
    "#qs.reports.metrics(returns, lookback_returns[3], mode='basic') #Compared weighted returns to one of the lookback periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs.reports.plots(returns, benchmark_monthly_returns, mode='full')\n",
    "#qs.reports.plots(returns, lookback_returns[3], mode='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('algo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad654615605a9a6561ac5d9ede85fd4a268de6bdfb45f58c8bc91a74f799d613"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
