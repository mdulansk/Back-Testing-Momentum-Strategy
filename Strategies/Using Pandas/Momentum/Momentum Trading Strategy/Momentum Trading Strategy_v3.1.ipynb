{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentum Trading Strategy implemented in Python on a 500 Stocks universe [Beginner friendly]\n",
    "By AlgoVibes (Youtube)\n",
    "https://www.youtube.com/watch?v=L2nhNvIAyBI\n",
    "\n",
    "Description:<br>\n",
    "Get list of S&P500 stocks<br>\n",
    "Download price data for all<br>\n",
    "Concatenate into one dataframe<br>\n",
    "Calculate percent change<br>\n",
    "Resample to monthly period<br>\n",
    "\n",
    "To Do:<br>\n",
    "    v3: Add daily trailing stop. After stop triggers, don't get back in until next month<br>\n",
    "        Alternatively, get back in after things go positive<br>\n",
    "        Implmentation:<br>\n",
    "            Option 1:  Don't resample data to monthly, just get a monthly index, then loop through monthly periods.<br>\n",
    "            Keep track of highest price as you iterate through daily prices. If price ever drops by more than stop amount, set rest of prices = cash return (0).<br>\n",
    "    v3.1<br>\n",
    "        Add new dataframe to keep track of our regime filters<br>\n",
    "        Add \"regime filter\" to help determine if you should be in cash. <br>\n",
    "        Filters:<br>\n",
    "            SPY < 200 day MA<br>\n",
    "            Market breadth increasing / shrinking<br>\n",
    "    v3.2:  Iterate through possible weighting combinations using itertools.<br>\n",
    "    v.3.3  Better stock selection:<br>\n",
    "        Calculate 30-day volume for all stocks in universe at beginning of start_date<br>\n",
    "        Take highest 100<br>\n",
    "        Calculate volume changes for top 100 stocks by volume, then select the ones with highest average volume increase over 30 day period (unusual volume)<br>\n",
    "    v3.3.1 Get more data so that there is more data for warmup indicators, then trim df for desired timeframe.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import sys\n",
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tseries.offsets import MonthEnd, DateOffset\n",
    "%matplotlib inline\n",
    "import quantstats as qs\n",
    "qs.extend_pandas() # # extend pandas functionality with metrics, etc.\n",
    "HOME_DIR = os.path.expanduser('~/')\n",
    "sys.path.append(f\"{HOME_DIR}Documents/Algo/Stock Price DB/\")\n",
    "#from get_ticker_data_from_db_v2 import process_ticker\n",
    "from StockPriceData import process_ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set variables \n",
    "data_folder = f'{HOME_DIR}Documents/Algo/Data'\n",
    "print(data_folder)\n",
    "start_date = '2000-01-01'#'1962-01-02'\n",
    "end_date = '2022-08-23'\n",
    "get_latest_data = True # Getting latest prices from DB is slow, so we can read previously created csv\n",
    "tickers = ['AAPL','AMZN','NFLX','AMD','NVDA','MSFT','WMT','IBM','KO','PSX','PG','BAC','WFC']\n",
    "benchmark = '^GSPC'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: when we get price df, we may want to replace all values below a certain threshold with 0 so that our algo doesn't\n",
    "# trade them since they may appear to have great returns at times even though they're uninvestible at the time such as when they first list.\n",
    "# We should replace small values from beginning of df until the price meets our threshold. We probably want to leave in prices when they go below our threshold later.\n",
    "def get_prices(tickers):\n",
    "    if get_latest_data == True:\n",
    "        prices, symbols = [],[]\n",
    "        for ticker in tickers:\n",
    "            print(f'Processing {ticker}')\n",
    "            try:\n",
    "                #df = process_ticker(ticker,end_date)['Adj_Close']\n",
    "                df = process_ticker(ticker,start_date,end_date)['Adj_Close']\n",
    "                if not df.empty:\n",
    "                    print(f'Appending {ticker} to prices and symbols lists')\n",
    "                    prices.append(df)\n",
    "                    symbols.append(ticker)\n",
    "            except:\n",
    "                print(f'Unable to download data for {ticker}')\n",
    "            \n",
    "        all_prices = pd.concat(prices,axis=1) #Concatenate all ticker price dfs to one df\n",
    "        all_prices.columns = symbols # Rename column names based on tickers\n",
    "        all_prices.to_csv(f\"{data_folder}/all_sp500_prices.csv\", index=True) #Index is date\n",
    "    else:\n",
    "        #all_prices = pd.read_csv(f\"{data_folder}/all_sp500_prices.csv\", index_col=[0], header=0, parse_dates=True) #Index is date\n",
    "        all_prices = pd.read_csv(f\"{data_folder}/all_sp500_prices.csv\", index_col='Date', parse_dates=True)\n",
    "        #all_prices.index = pd.to_datetime(all_prices.index) #Not necessary if dates are parsed properly\n",
    "    return(all_prices)\n",
    "\n",
    "all_prices = get_prices(tickers)\n",
    "# Don't use this function to get benchmark prices since it will overwrite all_sp500_prices.csv #benchmark_prices = get_prices(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_latest_data == True:\n",
    "    benchmark_prices = pd.DataFrame(process_ticker(benchmark,'2000-01-01',end_date)['Adj_Close'])#, name = benchmark) # Grab more data than we need since we'll be losing some to indicator warmup\n",
    "    benchmark_prices.to_csv('benchmark_prices.csv')\n",
    "else:\n",
    "    benchmark_prices = pd.read_csv('benchmark_prices.csv', index_col=['Date'], parse_dates=True)\n",
    "benchmark_prices.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prices\n",
    "#symbols\n",
    "#all_prices.index\n",
    "all_prices.head()\n",
    "all_prices.tail(10)\n",
    "#all_prices[all_prices > 0]\n",
    "latest_date_for_all = all_prices.dropna().index[-1] #This is the latest date where all tickers have data\n",
    "all_prices = all_prices.loc[:latest_date_for_all,:] #Trimming df to last date where all tickers had data\n",
    "all_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See  how much data we have for each ticker\n",
    "for column in all_prices.columns[:-1]:\n",
    "    prices = all_prices[column][all_prices[column]>0]\n",
    "    print(f'{column}:\\t{prices.index[0]} - {prices.index[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate monthly returns\n",
    "if get_latest_data == True:\n",
    "    all_daily_ret = all_prices.pct_change()\n",
    "    all_daily_ret['CASH'] = 0 # Add alternative for condition where everything is negative \n",
    "    all_daily_ret.to_csv(f\"{data_folder}/all_daily_ret.csv\", index=True) #Index is date\n",
    "    all_mtl_ret = all_prices.pct_change().resample('M').agg(lambda x : (x + 1).prod() -1)\n",
    "    all_mtl_ret['CASH'] = 0 # Add alternative for condition where everything is negative \n",
    "    all_mtl_ret.to_csv(f\"{data_folder}/all_mtl_ret.csv\", index=True) #Index is date\n",
    "else:\n",
    "    all_daily_ret = pd.read_csv(f\"{data_folder}/all_daily_ret.csv\", index_col='Date', parse_dates=True) #Index is date\n",
    "    all_mtl_ret = pd.read_csv(f\"{data_folder}/all_mtl_ret.csv\", index_col='Date', parse_dates=True) #Index is date\n",
    "# IMPORTANT: We need to remove NaN and inf values from percentage returns df since stocks that trade at very low prices or zero will have\n",
    "# crazy return calculations when prices go from 0 to anything or vice versa.\n",
    "all_daily_ret = all_daily_ret.replace([np.inf, -np.inf, np.nan], 0)\n",
    "all_mtl_ret = all_mtl_ret.replace([np.inf, -np.inf, np.nan], 0)\n",
    "#Create a new prices df of only companies that have prices going back to the earliest date\n",
    "#earliest_prices = all_prices.loc[:, all_prices.iloc[0] > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_daily_ret.index\n",
    "all_daily_ret.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mtl_ret.index\n",
    "all_mtl_ret.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead  of using something like the S&P500 as benchmark, we'll use an equal-weighted average of the returns for our defined assets\n",
    "benchmark_returns = benchmark_prices.pct_change().dropna() # Benchmark using index\n",
    "#benchmark_returns = all_prices.pct_change().dropna().mean(axis=1) # Benchmark using average prices for stocks in our universe\n",
    "benchmark_monthly_returns = benchmark_prices.pct_change().resample('M').agg(lambda x : (x + 1).prod() -1)\n",
    "#benchmark_monthly_returns = all_mtl_ret.mean(axis=1)\n",
    "#all_prices.tail().pct_change()#.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_returns\n",
    "benchmark_monthly_returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put it all together into a function that takes a lookback period (instead of just 12 months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regime_indicators(df,benchmark_prices):\n",
    "    lookback = 200\n",
    "    regime_df_index = df.index #Create new df from index of existing to hold weighted returns\n",
    "    regime_df = pd.DataFrame(index = regime_df_index)\n",
    "    rolling_avg_df = benchmark_prices.rolling(lookback).mean()\n",
    "    rolling_avg_df.dropna(inplace=True)\n",
    "    print(rolling_avg_df.head())\n",
    "    rolling_avg_df.plot(label='SPY MA',figsize=(16, 8))\n",
    "    \n",
    "regime_indicators(all_prices,benchmark_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trailing_stop_indiv(period_daily_ret, stop_loss):\n",
    "    # This function just calculates a trailing stop on returns of each stock that are passed to it.\n",
    "    # If the return for any portfolio stocks fall below the stop loss level,\n",
    "    # the remaining return values for that stock are  set to 0, which would be our return on the\n",
    "    # stock if we sold it on the next day.\n",
    "    peak_cum_return = 0 # This is to keep track of highest total return\n",
    "    cum_ret = 0\n",
    "    trailing_stop = cum_ret - stop_loss\n",
    "    ##print(f'{(period_daily_ret.index[0]).date()} - {(period_daily_ret.index[-1]).date()}\\t{period_daily_ret.columns.values}, Stop Loss:  {stop_loss}')\n",
    "    # Iterate through the dates in winning_returns_df\n",
    "    #for stock in period_daily_ret.columns:\n",
    "    for stock_idx in range(len(period_daily_ret.columns)):\n",
    "        #print(f'{stock_idx}\\t{period_daily_ret.columns[stock_idx]}')\n",
    "        #print(f'Calculating trailing stop for {period_daily_ret.columns[stock_idx]}')\n",
    "        for row in range(len(period_daily_ret)-1): # go through daily return for entire rolling lookback period\n",
    "            curr_date = period_daily_ret.iloc[row].name\n",
    "            period_ret = period_daily_ret.iloc[row,stock_idx]\n",
    "            #print(f'{curr_date}\\tPeriod return:  {period_ret}')\n",
    "            cum_ret += period_ret\n",
    "            if cum_ret > peak_cum_return:\n",
    "                peak_cum_return = cum_ret\n",
    "                #print(f'{curr_date}\\tPeak Cum. return:  {peak_cum_return}')\n",
    "                trailing_stop = peak_cum_return - stop_loss\n",
    "                #print(f'{curr_date}\\ttrailing_stop:  {trailing_stop}')\n",
    "            elif cum_ret <= trailing_stop:\n",
    "                ##print(f'{curr_date}\\t{period_daily_ret.columns[stock_idx]}\\tCumulative return ({cum_ret}) < stop loss level ({trailing_stop})  SELL!')\n",
    "                period_daily_ret.iloc[row+1:,stock_idx] = 0 # Set values for stock to 0 from next day to end of period df\n",
    "                break # Exit the loop since we're no longer in the stock\n",
    "        #print(f'period_daily_ret:  {period_daily_ret}')\n",
    "    return period_daily_ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(return_series):\n",
    "    tot_ret = round(qs.stats.comp(return_series),2)\n",
    "    sharpe_ratio = round(qs.stats.sharpe(return_series),2)\n",
    "    max_dd = round(qs.stats.max_drawdown(return_series),2)\n",
    "    return(tot_ret,sharpe_ratio,max_dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mom_long(all_mtl_ret, lookback):\n",
    "    #Calculate rolling returns based on provided lookback period and return df\n",
    "    #Loop though rolling return df and identify 50 winning stocks\n",
    "    #Get return for following month for each winning stock\n",
    "    #Append returns to list\n",
    "    #Return the return for the series of returns \n",
    "    all_mtl_ret_lb = all_mtl_ret.rolling(lookback).agg(lambda x: (x+1).prod() - 1) #Calculate return for period\n",
    "    #See https://stackoverflow.com/questions/67168187/cannot-called-a-function-using-agg-method-in-pandas\n",
    "    all_mtl_ret_lb.dropna(inplace=True)\n",
    "    rets = {}\n",
    "    for row in range(len(all_mtl_ret_lb)-1): #Loop through all monthly periods & identify winners and losers\n",
    "        #curr = all_mtl_ret_lb.iloc[row] # All stocks for period\n",
    "        curr = all_mtl_ret_lb.iloc[row][all_mtl_ret_lb.iloc[row].ge(0)] # Only stocks with prices >= 0\n",
    "        win = curr.nlargest(2) # Take the top 2 stocks\n",
    "        win_ret = all_mtl_ret.loc[win.name + MonthEnd(1), win.index] # Get returns for following month for selected stocks\n",
    "        win_mean = win_ret.mean() #Average return of top stocks for period\n",
    "        rets[curr.name]=win_mean\n",
    "    #print(f'rets: {rets}')\n",
    "    ret_series = pd.Series(rets, dtype='float64')\n",
    "    # Use QS to calculate strategy stats here or just return the return series and do it later.\n",
    "    tot_ret = round(qs.stats.comp(ret_series),2)\n",
    "    sharpe_ratio = round(qs.stats.sharpe(ret_series),2)\n",
    "    max_dd = round(qs.stats.max_drawdown(ret_series),2)\n",
    "    print(f'Lookback:  {lookback},  Tot Ret: {tot_ret},  Sharpe Ratio:  {sharpe_ratio},  Max DD:  {max_dd}')\n",
    "    # Calculate returns manually for comparison\n",
    "    tot_return = (pd.Series(rets, dtype='float64') + 1).prod() - 1\n",
    "    cum_returns = (ret_series + 1).cumprod()\n",
    "    #print(f'Tot Cum Return:  {round((cum_returns.iloc[-1])-1,2)}')\n",
    "    return (ret_series)\n",
    "    \n",
    "mom_return_series = mom_long(all_mtl_ret, 12)\n",
    "tot_ret,sharpe_ratio,max_dd = get_stats(mom_return_series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "daily momentum strategy:<br>\n",
    "    parameters:  daily returns df, lookback period<br>\n",
    "    1. copy daily returns df index only<br>\n",
    "    2. resample index to monthly - end of month<br>\n",
    "    3. iterate through monthly index:<br>\n",
    "        set index counter = 0<br>\n",
    "        set month start date index<br>\n",
    "        set end date to start date index + 1<br>\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mom_long_w_stop(all_daily_ret, lookback, stop_loss):\n",
    "    # We need to get date index for monthly resampled, then go though each period and apply trailing stop \n",
    "    # logic: keep track of highest price for period, then if price drops more than limit, set the rest of the period's return \n",
    "    # to the return of our safe asset, cash (0). After going through all periods, resample to monthly then pass to rest of function.\n",
    "    all_mtl_ret = all_daily_ret.resample('M').agg(lambda x : (x + 1).prod() -1)\n",
    "    all_mtl_ret_lb = all_mtl_ret.rolling(lookback).agg(lambda x: (x+1).prod() - 1) #Calculate rolling return for period\n",
    "    all_mtl_ret_lb.dropna(inplace=True)\n",
    "    rets = {}\n",
    "    rets_w_stop = {}\n",
    "    #print(f'all_daily_ret stocks:  {all_daily_ret.columns.values}, {len(all_daily_ret)} rows')\n",
    "    for row in range(len(all_mtl_ret_lb)-1): #Loop through all monthly periods & identify winners and losers\n",
    "    #for row in range(5): #Loop through all monthly periods & identify winners and losers\n",
    "        curr = all_mtl_ret_lb.iloc[row][all_mtl_ret_lb.iloc[row].ge(0)] # Only stocks with returns >= 0. We may want to change this to\n",
    "        #print(f'Curr stocks:  {curr.index[0]}, {curr.index[-1]}')\n",
    "        #print(f'Previous period end:  {all_mtl_ret_lb.iloc[row].name}')\n",
    "        # only select stocks with PRICES > 0 for each date so we don't get weird return values when prices go from 0 to anything. \n",
    "        win = curr.nlargest(2) # Take the top 2 stocks with highest returns for current period\n",
    "        last_period_end = win.name # Date for beginning of following month. We should increment this by 1 so we don't overlap with the end of last monthly period\n",
    "        period_start = last_period_end + DateOffset(days=1) # Increment next period start by one day to avoid overlap with prior period.\n",
    "        period_end = win.name+MonthEnd(1)# Date for end of following month\n",
    "        \n",
    "        # Modifications for trailing stop\n",
    "        if stop_loss != 0:\n",
    "            period_daily_ret = all_daily_ret.loc[period_start:period_end,win.index] # Daily returns of winning stocks for this period \n",
    "            #print(f'period_daily_ret:  {period_daily_ret.index[0]} - {period_daily_ret.index[-1]}')\n",
    "            period_daily_ret_modified = trailing_stop_indiv(period_daily_ret,stop_loss)\n",
    "            #print(f'period_daily_ret_modified:  {period_daily_ret_modified.index[0]} - {period_daily_ret_modified.index[-1]}')\n",
    "            #print(f'period_daily_ret_modified:  {period_daily_ret_modified}')\n",
    "            # Calculate the cumsum for the win_ret_modified DAILY returns to get equivalent monthly return for the period \n",
    "            win_ret = period_daily_ret_modified.cumsum().iloc[-1,:]           \n",
    "        else:\n",
    "            win_ret = all_mtl_ret.loc[win.name + MonthEnd(1), win.index] # Returns are based on following month's returns for current month's winning stocks\n",
    "        \n",
    "        win_mean = win_ret.mean() #Average return of top stocks for period\n",
    "        rets[curr.name]=win_mean\n",
    "        ret_series = pd.Series(rets, dtype='float64')        \n",
    "\n",
    "    return (ret_series)\n",
    "    \n",
    "monthly_returns = mom_long_w_stop(all_daily_ret, 12,  0.35) # Test\n",
    "tot_ret,sharpe_ratio,max_dd = get_stats(monthly_returns)\n",
    "print(f'Tot ret:  {tot_ret}\\tsharpe_ratio:  {sharpe_ratio}\\tmax_dd:  {max_dd}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rolling_returns(returns_df, window):\n",
    "    # Take returns_df and calculate rolling average based on passed window size\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(monthly_returns.describe())\n",
    "monthly_returns.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_monthly_returns.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate momentum results for several different lookback periods\n",
    "monthly_periods = None #120 # Specify \"None\" if you don't want to roll over the entire dataset\n",
    "lookback_periods = [3,6,12]\n",
    "#stop_loss = .05\n",
    "stop_losses = range(0,50,5) # start, stop, step\n",
    "#stop_losses = [30]\n",
    "# Improvement:  keep track of lookback period return series by adding to a dictionary, then we can reference later\n",
    "# to compare different weightings for top x lookback periods. This will allow us to try compare returns for different weightings.\n",
    "# (period 1 return * weight) + (period 2 return * wieght), etc\n",
    "'''You can compute a weighted average by multiplying its relative proportion or percentage by its value in sequence and\n",
    " adding those sums together. Thus, if a portfolio is made up of 55% stocks, 40% bonds, and 5% cash, those weights would be\n",
    "  multiplied by their annual performance to get a weighted average return.'''\n",
    "\n",
    "#all_mtl_ret_limited = all_mtl_ret.loc['2000-09-01':].copy()\n",
    "all_mtl_ret_limited = all_mtl_ret.iloc[:monthly_periods,:] # Trim df required number of periods (optional)\n",
    "print(f'Returns for {len(all_mtl_ret_limited)} months ({all_mtl_ret_limited.index[0].date()} - {all_mtl_ret_limited.index[-1].date()})')\n",
    "all_return_data = pd.DataFrame(columns=['lookback', 'stop', 'tot_ret', 'sharpe', 'max_dd'])\n",
    "index = 0 # Initialize to use as index for our statistics df\n",
    "for lookback in lookback_periods:\n",
    "  for stop_loss in stop_losses:\n",
    "    stop_loss = stop_loss/100\n",
    "    return_series = mom_long_w_stop(all_daily_ret, lookback, stop_loss)\n",
    "    tot_ret,sharpe_ratio,max_dd = get_stats(return_series)\n",
    "    # Append results to all_return_data. See https://datagy.io/empty-pandas-dataframe/ # Note: append is the specific case(axis=0, join='outer') of concat (being deprecated use concat)\n",
    "    current_stats = pd.DataFrame({'lookback':lookback,'stop':stop_loss,'tot_ret':tot_ret,'sharpe':sharpe_ratio,'max_dd':max_dd},index=[index])\n",
    "    all_return_data = pd.concat([all_return_data, current_stats])\n",
    "    index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameters and returns\n",
    "#print(f'all_return_data:\\n  {all_return_data}')\n",
    "all_return_data.sort_values(by='sharpe', ascending=False,inplace=True)\n",
    "print(all_return_data[:10])\n",
    "#TO DO\n",
    "# Calculate returns over rolling monthly periods and average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_returns(criteria='tot_ret'):\n",
    "    best_returns = {}\n",
    "    for lookback in all_return_data['lookback'].unique(): # Get a list of lookback periods from the return data df\n",
    "        lookback_results=(all_return_data[all_return_data['lookback'] == lookback]).copy().reset_index(drop=True) #Get subset of return data df based on current lookback\n",
    "        max_index = (lookback_results[criteria].idxmax()) # Get the index of the best return for current lookback\n",
    "        stop_loss = all_return_data.iloc[max_index].stop # Get the stop loss that was used.\n",
    "        print(f'Best return combo for {lookback} month lookback:')\n",
    "        print(lookback_results.iloc[[max_index]])\n",
    "        best_returns[lookback] = mom_long_w_stop(all_daily_ret, lookback, stop_loss) # Get the return series for this combo since we didn't reference it anywhere\n",
    "        \n",
    "    return best_returns # Return dictionary containing best return series for each lookback period\n",
    "    #qs.reports.metrics(best_returns_series, benchmark_monthly_returns, mode='basic') # Compared returns to benchmark\n",
    "    #print(get_stats(best_returns_series))\n",
    "\n",
    "best_returns = get_best_returns('tot_ret') #Get the returns with highest total return for each lookback period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_returns[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_ret_b,sharpe_ratio_b,max_dd_b = get_stats(benchmark_monthly_returns)\n",
    "print(f'Benchmark return periods:  {benchmark_monthly_returns.shape[0]}')\n",
    "print(f'Benchmark tot_ret: {tot_ret_b}\\t sharpe: {sharpe_ratio_b}\\tmax_dd: {max_dd_b}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at returns over various timeframes to see how strategy performs over different periods of time, instead of just looking at total period\n",
    "# Split return data into chunks and iterate over chunks to evaluate min, max, avg returns for the periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section loops through several lookback periods which are based to our strategy.\n",
    "# The return for each period is referenced in a new dataframe which we use to weight\n",
    "# the different returns based on different parameters.\n",
    "#period_weights = [.3333, .3333, .3333]\n",
    "period_weights = [.5, 0, .5]\n",
    "weighted_returns_index = all_mtl_ret_limited.index #Create new df from index of existing to hold weighted returns\n",
    "weighted_returns = pd.DataFrame(index = weighted_returns_index)\n",
    "index = 0\n",
    "for period_return in best_returns.keys():\n",
    "    lookback = lookback_periods[index]\n",
    "    ##print(f'Period weight for {lookback} period lookback:  {period_weights[index]}')\n",
    "    weighted_return = best_returns[period_return]*period_weights[index]\n",
    "    ##print(f'weighted_return for {lookback} period lookback:  {weighted_return}')\n",
    "    weighted_returns[lookback] = weighted_return\n",
    "    index+=1\n",
    "weighted_returns = weighted_returns.replace([np.inf, -np.inf, np.nan], 0)\n",
    "returns = weighted_returns.sum(axis=1) # Add up weighted returns to get total return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass returns and benchmark to QuantStats to get return metrics\n",
    "#qs.reports.metrics(returns, '^GSPC', mode='basic')\n",
    "qs.reports.metrics(returns, benchmark_monthly_returns, mode='basic') # Compared returns to benchmark\n",
    "#qs.reports.metrics(returns, best_returns[3], mode='basic') #Compared weighted returns to one of the lookback periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs.reports.plots(returns, benchmark_monthly_returns, mode='full')\n",
    "#qs.reports.plots(returns, best_returns[3], mode='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e26213f1be164962b461468972fd89f374928e979d98cd024b425d7ac8225448"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
